{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027e0316-90cb-424f-bc43-3c0496dafeda",
   "metadata": {},
   "source": [
    "## Homework: Vector Search\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "Qdrant uses [fastembed](https://github.com/qdrant/fastembed)\n",
    "under the hood to turn text into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29189a62-aed0-4757-9a80-789127faca31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:17:08.221103Z",
     "start_time": "2025-07-02T10:17:05.120348Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastembed in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (0.33.0)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (0.7.3)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.26 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (1.26.4)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (1.22.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (10.3.0)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (0.1.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (0.21.1)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from fastembed) (4.66.4)\n",
      "Requirement already satisfied: filelock in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (1.1.3)\n",
      "Requirement already satisfied: coloredlogs in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (3.20.3)\n",
      "Requirement already satisfied: sympy in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from requests<3.0,>=2.31->fastembed) (2024.8.30)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sparsh-raj/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a4943-09ef-404c-b431-19ef9607993f",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query\n",
    "\n",
    "Embed the query: `'I just discovered the course. Can I join now?'`.\n",
    "Use the `'jinaai/jina-embeddings-v2-small-en'` model. \n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?\n",
    "\n",
    "* -0.51\n",
    "* -0.11\n",
    "* 0\n",
    "* 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e0ffc57-8db8-43e3-a3e8-ef04519a9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f7ebfbf-339d-42f9-980f-5b9d8a57908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbedding(model_name = 'jinaai/jina-embeddings-v2-small-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e654e71-9f95-47b6-b878-c5cf919b8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just discovered the course. Can I join now?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a561b312-433e-4da7-9770-be8466e121c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = list(model.embed(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02afd993-19bc-4519-9004-5d68ded42f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_array = embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ef752d6-2dba-44e7-883b-7e37b7a0ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the array is 512 and the minmal value in the array is -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "print(\"The dimension of the array is {} and the minmal value in the array is {}\".format(len(embeddings_array) ,min(embeddings_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9712d0a-d7ff-4fa9-b5c1-4ba4cb722192",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "\n",
    "The vectors that our embedding model returns are already normalized: their length is 1.0.\n",
    "\n",
    "You can check that by using the `norm` function:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.linalg.norm(q)\n",
    "```\n",
    "\n",
    "Which means that we can simply compute the dot product between\n",
    "two vectors to learn the cosine similarity between them.\n",
    "\n",
    "For example, if you compute the cosine of the query vector with itself, the result will be 1.0:\n",
    "\n",
    "```python\n",
    "q.dot(q)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecac28a-d532-428e-a8e4-f7652ba0ae1b",
   "metadata": {},
   "source": [
    "## Q2. Cosine similarity with another vector\n",
    "\n",
    "Now let's embed this document:\n",
    "\n",
    "```python\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "```\n",
    "\n",
    "What's the cosine similarity between the vector for the query\n",
    "and the vector for the document?\n",
    "\n",
    "* 0.3\n",
    "* 0.5\n",
    "* 0.7\n",
    "* 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17f3c4e7-643d-4f43-95c2-be84a3c980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0c5013c-bbdc-40bb-8c56-a9bacb8f89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Can I still join the course after the start date?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a578232-6db8-4f35-8010-15a20fd6dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_doc = list(model.embed(doc))\n",
    "embeddings_array_doc = embeddings_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ea77027-94d0-4209-93fe-83e5b14c512d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, -0.12396320482168117)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_array_doc) ,min(embeddings_array_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a5cd41c-094e-42d6-b82e-0a483d555e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9999999999999999)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(embeddings_array), np.linalg.norm(embeddings_array_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ac833f4-0960-467f-832e-451c9355c6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the vector for the query and the vector for the document is:\n",
      " 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "print(\"The cosine similarity between the vector for the query and the vector for the document is:\\n\", embeddings_array.dot(embeddings_array_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a5abc-94d6-450e-a116-910119a78019",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine\n",
    "\n",
    "For Q3 and Q4 we will use these documents:\n",
    "\n",
    "```python\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "```\n",
    "\n",
    "Compute the embeddings for the text field, and compute the \n",
    "cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):\n",
    "\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "Hint: if you put all the embeddings of the text field in one matrix `V` (a single 2-dimensional numpy array), then\n",
    "computing the cosine becomes a matrix multiplication:\n",
    "\n",
    "```python\n",
    "V.dot(q)\n",
    "```\n",
    "\n",
    "If this hint is rather confusing you than helping, feel free\n",
    "to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e557a9e7-5654-4f8e-8371-0734f6d7fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6b69931-e157-44db-a748-db18e17849c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:54:26.723863Z",
     "start_time": "2025-07-02T10:54:26.652259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hint: if you put all the embeddings of the text field in one matrix `V` (a single 2-dimensional numpy array), then\n",
    "# computing the cosine becomes a matrix multiplication:\n",
    "\n",
    "embeddings_vector = np.array([list(model.embed(doc['text']))[0] for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e96e6b7-619b-498d-b3b5-4a5c8bfd0920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:54:27.958647Z",
     "start_time": "2025-07-02T10:54:27.955728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0249525 , -0.0396454 , -0.00437672, ...,  0.06779866,\n",
       "         0.0377203 , -0.00470724],\n",
       "       [-0.0594709 , -0.08523984,  0.01292091, ...,  0.09599709,\n",
       "         0.05420843, -0.00029461],\n",
       "       [-0.06846454, -0.04079098,  0.04998121, ...,  0.06578071,\n",
       "         0.02872077, -0.01115215],\n",
       "       [-0.04640506, -0.02555229,  0.02241224, ...,  0.03410312,\n",
       "         0.06813592, -0.0064033 ],\n",
       "       [-0.05394912, -0.04693814,  0.00794725, ...,  0.05402997,\n",
       "         0.03033385, -0.01254518]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9086fc2afa6c288a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:57:54.639172Z",
     "start_time": "2025-07-02T10:57:54.620207Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = embeddings_vector.dot(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2ac09ead53802b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:58:03.453434Z",
     "start_time": "2025-07-02T10:58:03.450178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76296847, 0.81823782, 0.80853974, 0.7133079 , 0.73044992])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a8216d38fc57cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T10:58:19.336304Z",
     "start_time": "2025-07-02T10:58:19.333329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document index with highest similarity: 1\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmax(similarities)\n",
    "print(\"Document index with highest similarity:\", best_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba20605-80fa-4607-ae58-f57f2d5a95c2",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n",
    "\n",
    "Now let's calculate a new field, which is a concatenation of\n",
    "`question` and `text`:\n",
    "\n",
    "```python\n",
    "full_text = doc['question'] + ' ' + doc['text']\n",
    "``` \n",
    "\n",
    "Embed this field and compute the cosine between it and the\n",
    "query vector. What's the highest scoring document?\n",
    "\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "Is it different from Q3? If yes, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9103db0-c85e-4f14-81bb-79be0cf35b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_vector_q4 = np.array([list(model.embed(doc['question']+doc['text']))[0] for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab5850a6-1ed1-45e5-ac94-2543f9cd6e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85145432, 0.84365942, 0.8408287 , 0.7755158 , 0.80860078])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_q4 = embeddings_vector_q4.dot(embeddings_array)\n",
    "similarities_q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1eb3fe9f-5f5d-4774-a3fe-8edcdff968ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document index with highest similarity: 0\n"
     ]
    }
   ],
   "source": [
    "best_idx_q4 = np.argmax(similarities_q4)\n",
    "print(\"Document index with highest similarity:\", best_idx_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a7226-211f-4939-aea6-68ed20e23196",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model\n",
    "\n",
    "Now let's select a smaller embedding model.\n",
    "What's the smallest dimensionality for models in fastembed?\n",
    "\n",
    "- 128\n",
    "- 256\n",
    "- 384\n",
    "- 512\n",
    "\n",
    "One of these models is `BAAI/bge-small-en`. Let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ae39a940ef0f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>dim</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 256...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-xs</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.067</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAAI/bge-small-zh-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), Chinese, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.090</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qdrant/clip-ViT-B-32-text</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.250</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jinaai/jina-embeddings-v2-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-code</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5-Q</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thenlper/gte-base</td>\n",
       "      <td>General text embeddings, Unimodal (text), supp...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.440</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-es</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-zh</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BAAI/bge-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.420</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jinaai/jina-clip-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m-long</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 204...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.540</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.210</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-de</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>mit</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-l</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jinaai/jina-embeddings-v3</td>\n",
       "      <td>Multi-task unimodal (text) embedding model, mu...</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>2.290</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'retrieval.query': 0, 'retrieval.passage': 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0              sentence-transformers/all-MiniLM-L6-v2   \n",
       "1                 snowflake/snowflake-arctic-embed-xs   \n",
       "2                              BAAI/bge-small-en-v1.5   \n",
       "3                  snowflake/snowflake-arctic-embed-s   \n",
       "4   sentence-transformers/paraphrase-multilingual-...   \n",
       "5                                   BAAI/bge-small-en   \n",
       "6                              BAAI/bge-small-zh-v1.5   \n",
       "7                           Qdrant/clip-ViT-B-32-text   \n",
       "8                  jinaai/jina-embeddings-v2-small-en   \n",
       "9                        nomic-ai/nomic-embed-text-v1   \n",
       "10  sentence-transformers/paraphrase-multilingual-...   \n",
       "11                jinaai/jina-embeddings-v2-base-code   \n",
       "12                   nomic-ai/nomic-embed-text-v1.5-Q   \n",
       "13                     nomic-ai/nomic-embed-text-v1.5   \n",
       "14                                  thenlper/gte-base   \n",
       "15                  jinaai/jina-embeddings-v2-base-es   \n",
       "16                  jinaai/jina-embeddings-v2-base-zh   \n",
       "17                                   BAAI/bge-base-en   \n",
       "18                  jinaai/jina-embeddings-v2-base-en   \n",
       "19                                jinaai/jina-clip-v1   \n",
       "20            snowflake/snowflake-arctic-embed-m-long   \n",
       "21                 snowflake/snowflake-arctic-embed-m   \n",
       "22                              BAAI/bge-base-en-v1.5   \n",
       "23                  jinaai/jina-embeddings-v2-base-de   \n",
       "24                     intfloat/multilingual-e5-large   \n",
       "25                 snowflake/snowflake-arctic-embed-l   \n",
       "26                                 thenlper/gte-large   \n",
       "27                 mixedbread-ai/mxbai-embed-large-v1   \n",
       "28                             BAAI/bge-large-en-v1.5   \n",
       "29                          jinaai/jina-embeddings-v3   \n",
       "\n",
       "                                          description       license  \\\n",
       "0   Text embeddings, Unimodal (text), English, 256...    apache-2.0   \n",
       "1   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "2   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "3   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "4   Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "5   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "6   Text embeddings, Unimodal (text), Chinese, 512...           mit   \n",
       "7   Text embeddings, Multimodal (text&image), Engl...           mit   \n",
       "8   Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "9   Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "10  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "11  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "12  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "13  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "14  General text embeddings, Unimodal (text), supp...           mit   \n",
       "15  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "16  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "17  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "18  Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "19  Text embeddings, Multimodal (text&image), Engl...    apache-2.0   \n",
       "20  Text embeddings, Unimodal (text), English, 204...    apache-2.0   \n",
       "21  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "22  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "23  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "24  Text embeddings, Unimodal (text), Multilingual...           mit   \n",
       "25  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "26  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "27  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "28  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "29  Multi-task unimodal (text) embedding model, mu...  cc-by-nc-4.0   \n",
       "\n",
       "    size_in_GB   dim                                              tasks  \n",
       "0        0.090   384                                                 {}  \n",
       "1        0.090   384                                                 {}  \n",
       "2        0.067   384                                                 {}  \n",
       "3        0.130   384                                                 {}  \n",
       "4        0.220   384                                                 {}  \n",
       "5        0.130   384                                                 {}  \n",
       "6        0.090   512                                                 {}  \n",
       "7        0.250   512                                                 {}  \n",
       "8        0.120   512                                                 {}  \n",
       "9        0.520   768                                                 {}  \n",
       "10       1.000   768                                                 {}  \n",
       "11       0.640   768                                                 {}  \n",
       "12       0.130   768                                                 {}  \n",
       "13       0.520   768                                                 {}  \n",
       "14       0.440   768                                                 {}  \n",
       "15       0.640   768                                                 {}  \n",
       "16       0.640   768                                                 {}  \n",
       "17       0.420   768                                                 {}  \n",
       "18       0.520   768                                                 {}  \n",
       "19       0.550   768                                                 {}  \n",
       "20       0.540   768                                                 {}  \n",
       "21       0.430   768                                                 {}  \n",
       "22       0.210   768                                                 {}  \n",
       "23       0.320   768                                                 {}  \n",
       "24       2.240  1024                                                 {}  \n",
       "25       1.020  1024                                                 {}  \n",
       "26       1.200  1024                                                 {}  \n",
       "27       0.640  1024                                                 {}  \n",
       "28       1.200  1024                                                 {}  \n",
       "29       2.290  1024  {'retrieval.query': 0, 'retrieval.passage': 1,...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "supported_models = (\n",
    "    pd.DataFrame(TextEmbedding.list_supported_models())\n",
    "    .sort_values(\"dim\")\n",
    "    .drop(columns=[\"sources\", \"model_file\", \"additional_files\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "supported_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b63c8563-c7c2-4f98-914e-7fbbbf59aca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:14:01.286183Z",
     "start_time": "2025-07-02T11:14:01.262282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>dim</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.067</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 256...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-xs</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  \\\n",
       "2                             BAAI/bge-small-en-v1.5   \n",
       "0             sentence-transformers/all-MiniLM-L6-v2   \n",
       "1                snowflake/snowflake-arctic-embed-xs   \n",
       "3                 snowflake/snowflake-arctic-embed-s   \n",
       "5                                  BAAI/bge-small-en   \n",
       "4  sentence-transformers/paraphrase-multilingual-...   \n",
       "\n",
       "                                         description     license  size_in_GB  \\\n",
       "2  Text embeddings, Unimodal (text), English, 512...         mit       0.067   \n",
       "0  Text embeddings, Unimodal (text), English, 256...  apache-2.0       0.090   \n",
       "1  Text embeddings, Unimodal (text), English, 512...  apache-2.0       0.090   \n",
       "3  Text embeddings, Unimodal (text), English, 512...  apache-2.0       0.130   \n",
       "5  Text embeddings, Unimodal (text), English, 512...         mit       0.130   \n",
       "4  Text embeddings, Unimodal (text), Multilingual...  apache-2.0       0.220   \n",
       "\n",
       "   dim tasks  \n",
       "2  384    {}  \n",
       "0  384    {}  \n",
       "1  384    {}  \n",
       "3  384    {}  \n",
       "5  384    {}  \n",
       "4  384    {}  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model with the smallest dimensionality\n",
    "smallest_model = supported_models[supported_models[\"dim\"] == supported_models[\"dim\"].min()].sort_values('size_in_GB')\n",
    "smallest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce0a3a-5194-4445-87a3-83587ade95d8",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)\n",
    "\n",
    "For the last question, we will use more documents.\n",
    "\n",
    "We will select only FAQ records from our ml zoomcamp:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "```\n",
    "\n",
    "Add them to qdrant using the model form Q5.\n",
    "\n",
    "When adding the data, use both question and answer fields:\n",
    "\n",
    "```python\n",
    "text = doc['question'] + ' ' + doc['text']\n",
    "```\n",
    "\n",
    "After the data is inserted, use the question from Q1 for querying the collection.\n",
    "\n",
    "What's the highest score in the results?\n",
    "(The score for the first returned record):\n",
    "\n",
    "- 0.97\n",
    "- 0.87\n",
    "- 0.77\n",
    "- 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb202e22-e932-4670-a0df-5978f545d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35e2bbfd-c0eb-4a31-870a-34bd8fc5c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4cba144-848c-41ac-a7a7-035a62c20d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49f8458d-3e43-4406-b14a-e28ab1c39bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = 'BAAI/bge-small-en'\n",
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-rag-homework\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY, \n",
    "        distance=models.Distance.COSINE \n",
    "    )\n",
    ")\n",
    "\n",
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=models.Document(text=doc['question'] + doc['text'], model=model_handle),\n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5bee47c9-42c4-4f67-abdd-7614b3147726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2160104-2dfb-41e2-a334-ad9bc11e433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "425a83f9-cef9-41ba-b0c5-bd15e782eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just discovered the course. Can I join now?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8f2a36f0-eeab-4f5e-b5b6-83018de3d358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:32:43.794642Z",
     "start_time": "2025-07-02T11:32:43.780268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=449, version=0, score=0.8703172, payload={'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "678c574a-23ee-4aec-b621-d6fe69a325a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T11:33:00.655394Z",
     "start_time": "2025-07-02T11:33:00.640198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score in the results is: 0.8703172\n"
     ]
    }
   ],
   "source": [
    "print(\"The highest score in the results is: {}\".format(results.points[0].score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
