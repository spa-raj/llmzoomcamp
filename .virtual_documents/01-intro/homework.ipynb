














import requests 

docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'
docs_response = requests.get(docs_url)
documents_raw = docs_response.json()

documents = []-

for course in documents_raw:
    course_name = course['course']

    for doc in course['documents']:
        doc['course'] = course_name
        documents.append(doc)


documents[0]








pip install elasticsearch


pip install ipywidgets


from elasticsearch import Elasticsearch
es_client = Elasticsearch('http://localhost:9200')
es_client.info()


index_settings = {
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0
    },
    "mappings": {
        "properties": {
            "text": {"type": "text"},
            "section": {"type": "text"},
            "question": {"type": "text"},
            "course": {"type": "keyword"}
        }
    }
}

index_name = "course-questions"

es_client.indices.create(index=index_name, body=index_settings)


from tqdm.auto import tqdm

for doc in tqdm(documents):
    es_client.index(index=index_name, document=doc)





def elastic_search(query):
    search_query = {
        "size": 5,
        "query": {
            "bool": {
                "must": {
                    "multi_match": {
                        "query": query,
                        "fields": ["question^4", "text"],
                        "type": "best_fields"
                    }
                }
            }
        }
    }

    response = es_client.search(index=index_name, body=search_query)

    result_docs = []

    for hit in response['hits']['hits']:
        result_docs.append(hit)

    return result_docs


query = "How do execute a command on a Kubernetes pod?"


top_results = elastic_search(query)
top_results


max_score = max(r["_score"] for r in top_results)


 print("Top ranking result score is: ", max_score)





def elastic_search2(query):
    search_query = {
        "size": 3,
        "query": {
            "bool": {
                "must": {
                    "multi_match": {
                        "query": query,
                        "fields": ["question^4", "text"],
                        "type": "best_fields"
                    }
                },
                "filter": {
                    "term": {
                        "course": "machine-learning-zoomcamp"
                    }
                }
            }
        }
    }

    response = es_client.search(index=index_name, body=search_query)

    result_docs = []

    for hit in response['hits']['hits']:
        result_docs.append(hit['_source'])

    return result_docs


query = "How do copy a file to a Docker container?"


result = elastic_search2(query)
result


print("The 3rd question returned by the search engine is:\n",result[2]['question'])





def build_prompt(query, search_results):
    prompt_template = """
You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.
Use only the facts from the CONTEXT when answering the QUESTION.

QUESTION: {question}

CONTEXT:
{context}
""".strip()

    context = ""

    for doc in search_results:
        context = context + f"Q: {doc['question']}\nA: {doc['text']}\n\n"
        
    prompt = prompt_template.format(question=query, context=context).strip()
    return prompt


prompt = build_prompt(query, result)
prompt


print("The length of the resulting prompt is:", len(prompt))





pip install tiktoken


import tiktoken


encoding = tiktoken.encoding_for_model("gpt-4o")


encoded_prompt = encoding.encode(prompt)


print("Our prompt have", len(encoded_prompt), "tokens")





from openai import OpenAI
client = OpenAI()


def llm(prompt):
    response = client.chat.completions.create(
        model='gpt-4.1',
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content


def rag(query):
    search_results = elastic_search2(query)
    prompt = build_prompt(query, search_results)
    answer = llm(prompt)
    return answer


output = rag(query)
print(output)








encoded_output = encoding.encode(output)


print("Our output have", len(encoded_output), "tokens")






